{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import / Feature Engineering / Preprocessing / Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import quandl\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load minutely_data from a csv file\n",
    "\n",
    "minutely_data = pd.read_csv('coinbase_minute.csv')\n",
    "minutely_data.set_index('Timestamp', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get lagged returns\n",
    "\n",
    "parameter_lagged_return_1_window = 15\n",
    "parameter_lagged_return_2_window = 30\n",
    "\n",
    "minutely_data['return_answer'] = np.log(minutely_data.Close /  minutely_data.Close.shift(1))\n",
    "\n",
    "minutely_data['return'] = np.log(minutely_data.Close.shift(1) /  minutely_data.Close.shift(2))\n",
    "minutely_data['lagged_return_1'] = np.log(minutely_data.Close.shift(1) / minutely_data.Close.shift(parameter_lagged_return_1_window+1))\n",
    "minutely_data['lagged_return_2'] = np.log(minutely_data.Close.shift(1) / minutely_data.Close.shift(parameter_lagged_return_2_window+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define what the zscore is\n",
    "\n",
    "def zscore(x, window):\n",
    "    r = x.rolling(window=window)\n",
    "    m = r.mean().shift(1)\n",
    "    s = r.std(ddof=0).shift(1)\n",
    "    z = (x-m)/s\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Zscore on return ranges\n",
    "\n",
    "parameter_zscore_return_window = 1*60*24\n",
    "parameter_zscore_return_1_window = 1*60*24\n",
    "parameter_zscore_return_2_window = 5*60*24\n",
    "\n",
    "minutely_data['zscore_return'] = zscore(minutely_data['return'], parameter_zscore_return_window)\n",
    "minutely_data['zscore_return_1'] = zscore(minutely_data['return'], parameter_zscore_return_1_window)\n",
    "minutely_data['zscore_return_2'] = zscore(minutely_data['return'], parameter_zscore_return_2_window)\n",
    "\n",
    "parameter_zscore_lagged_return_1_window = 1*60*24\n",
    "parameter_zscore_lagged_return_2_window = 1*60*24\n",
    "\n",
    "minutely_data['zscore_lagged_return_1'] = zscore(minutely_data['lagged_return_1'], parameter_zscore_lagged_return_1_window)\n",
    "minutely_data['zscore_lagged_return_2'] = zscore(minutely_data['lagged_return_2'], parameter_zscore_lagged_return_2_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Price moving averages\n",
    "\n",
    "parameter_price_to_moving_average_return_1_window = 15\n",
    "parameter_price_to_moving_average_return_2_window = 60\n",
    "parameter_price_to_moving_average_return_3_window = 240\n",
    "\n",
    "minutely_data['price_to_moving_average_price_1'] = minutely_data.Close.shift(1) / minutely_data.Close.rolling(parameter_price_to_moving_average_return_1_window).mean().shift(1)\n",
    "minutely_data['price_to_moving_average_price_2'] = minutely_data.Close.shift(1) / minutely_data.Close.rolling(parameter_price_to_moving_average_return_2_window).mean().shift(1)\n",
    "minutely_data['price_to_moving_average_price_3'] = minutely_data.Close.shift(1) / minutely_data.Close.rolling(parameter_price_to_moving_average_return_3_window).mean().shift(1)\n",
    "\n",
    "parameter_zscore_price_to_moving_average_return_1_window = 5*60*24\n",
    "parameter_zscore_price_to_moving_average_return_2_window = 5*60*24\n",
    "parameter_zscore_price_to_moving_average_return_3_window = 5*60*24\n",
    "\n",
    "minutely_data['zscore_price_to_moving_average_price_1'] = zscore(minutely_data['price_to_moving_average_price_1'],parameter_zscore_price_to_moving_average_return_1_window)\n",
    "minutely_data['zscore_price_to_moving_average_price_2'] = zscore(minutely_data['price_to_moving_average_price_2'],parameter_zscore_price_to_moving_average_return_2_window)\n",
    "minutely_data['zscore_price_to_moving_average_price_3'] = zscore(minutely_data['price_to_moving_average_price_3'],parameter_zscore_price_to_moving_average_return_3_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Price moving average crossovers\n",
    "\n",
    "parameter_crossover_top_moving_average_1_window = 15\n",
    "parameter_crossover_bottom_moving_average_1_window = 30\n",
    "\n",
    "parameter_crossover_top_moving_average_2_window = 60\n",
    "parameter_crossover_bottom_moving_average_2_window = 240\n",
    "\n",
    "minutely_data['moving_average_crossover_1'] = minutely_data.Close.rolling(parameter_crossover_top_moving_average_1_window).mean().shift(1) / minutely_data.Close.rolling(parameter_crossover_bottom_moving_average_1_window).mean().shift(1) \n",
    "minutely_data['moving_average_crossover_2'] = minutely_data.Close.rolling(parameter_crossover_top_moving_average_2_window).mean().shift(1) / minutely_data.Close.rolling(parameter_crossover_bottom_moving_average_2_window).mean().shift(1)\n",
    "\n",
    "parameter_zscore_moving_average_crossover_1_window = 5*60*24\n",
    "parameter_zscore_moving_average_crossover_2_window = 5*60*24\n",
    "\n",
    "minutely_data['zscore_moving_average_crossover_1'] = zscore(minutely_data['moving_average_crossover_1'], parameter_zscore_moving_average_crossover_1_window)\n",
    "minutely_data['zscore_moving_average_crossover_2'] = zscore(minutely_data['moving_average_crossover_2'], parameter_zscore_moving_average_crossover_2_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Price acceleration\n",
    "\n",
    "parameter_acceleration_top_price_to_moving_average_1_window = 15\n",
    "parameter_acceleration_top_price_to_moving_average_2_window = 60\n",
    "\n",
    "parameter_acceleration_bottom_price_to_moving_average_1_window = 15\n",
    "parameter_acceleration_bottom_price_to_moving_average_2_window = 60\n",
    "\n",
    "parameter_acceleration_average_bottom_price_to_moving_average_1_window = 15\n",
    "parameter_acceleration_average_bottom_price_to_moving_average_2_window = 15\n",
    "\n",
    "minutely_data['temp_1'] = minutely_data.Close.shift(1) / minutely_data.Close.rolling(parameter_acceleration_bottom_price_to_moving_average_1_window).mean().shift(1)\n",
    "minutely_data['temp_2'] = minutely_data.Close.shift(1) / minutely_data.Close.rolling(parameter_acceleration_bottom_price_to_moving_average_2_window).mean().shift(1)\n",
    "\n",
    "minutely_data['acceleration_1'] = (minutely_data.Close.shift(1) / minutely_data.Close.rolling(parameter_acceleration_top_price_to_moving_average_1_window).mean().shift(1)) / (minutely_data.temp_1.rolling(parameter_acceleration_average_bottom_price_to_moving_average_1_window).mean())\n",
    "minutely_data['acceleration_2'] = (minutely_data.Close.shift(1) / minutely_data.Close.rolling(parameter_acceleration_top_price_to_moving_average_2_window).mean().shift(1)) / (minutely_data.temp_2.rolling(parameter_acceleration_average_bottom_price_to_moving_average_2_window).mean())\n",
    "\n",
    "minutely_data = minutely_data.drop(['temp_1','temp_2'], axis=1)\n",
    "\n",
    "parameter_zscore_acceleration_1_window = 15*60*24\n",
    "parameter_zscore_acceleration_2_window = 15*60*24\n",
    "\n",
    "minutely_data['zscore_acceleration_1'] = zscore(minutely_data['acceleration_1'], parameter_zscore_acceleration_1_window)\n",
    "minutely_data['zscore_acceleration_2'] = zscore(minutely_data['acceleration_2'], parameter_zscore_acceleration_2_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Zscore on trading volume\n",
    "\n",
    "parameter_zscore_volume_1_window = 1*60*24\n",
    "parameter_zscore_volume_2_window = 5*60*24\n",
    "parameter_zscore_volume_3_window = 15*60*24\n",
    "\n",
    "minutely_data['zscore_volume_1'] = zscore(minutely_data['Volume_(Currency)'].shift(1), parameter_zscore_volume_1_window)\n",
    "minutely_data['zscore_volume_2'] = zscore(minutely_data['Volume_(Currency)'].shift(1), parameter_zscore_volume_2_window)\n",
    "minutely_data['zscore_volume_3'] = zscore(minutely_data['Volume_(Currency)'].shift(1), parameter_zscore_volume_3_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Volume moving average\n",
    "\n",
    "parameter_volume_moving_average_1_window = 15\n",
    "parameter_volume_moving_average_2_window = 60\n",
    "parameter_volume_moving_average_3_window = 240\n",
    "\n",
    "minutely_data['volume_moving_average_1'] = minutely_data['Volume_(Currency)'].shift(1) / minutely_data['Volume_(Currency)'].rolling(parameter_volume_moving_average_1_window).mean().shift(1)\n",
    "minutely_data['volume_moving_average_2'] = minutely_data['Volume_(Currency)'].shift(1) / minutely_data['Volume_(Currency)'].rolling(parameter_volume_moving_average_2_window).mean().shift(1)\n",
    "minutely_data['volume_moving_average_3'] = minutely_data['Volume_(Currency)'].shift(1) / minutely_data['Volume_(Currency)'].rolling(parameter_volume_moving_average_3_window).mean().shift(1)\n",
    "\n",
    "parameter_zscore_volume_moving_average_1_window = 15*24*60\n",
    "parameter_zscore_volume_moving_average_2_window = 15*24*60\n",
    "parameter_zscore_volume_moving_average_3_window = 15*24*60\n",
    "\n",
    "minutely_data['zscore_volume_moving_average_1'] = zscore(minutely_data['volume_moving_average_1'], parameter_zscore_volume_moving_average_1_window)\n",
    "minutely_data['zscore_volume_moving_average_2'] = zscore(minutely_data['volume_moving_average_2'], parameter_zscore_volume_moving_average_2_window)\n",
    "minutely_data['zscore_volume_moving_average_3'] = zscore(minutely_data['volume_moving_average_3'], parameter_zscore_volume_moving_average_3_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Price volatility\n",
    "\n",
    "parameter_price_volatility_1_window = 15\n",
    "parameter_price_volatility_2_window = 60\n",
    "parameter_price_volatility_3_window = 240\n",
    "\n",
    "minutely_data['price_volatility_1'] = minutely_data['return'].rolling(parameter_price_volatility_1_window).std(0).shift(1)\n",
    "minutely_data['price_volatility_2'] = minutely_data['return'].rolling(parameter_price_volatility_2_window).std(0).shift(1)\n",
    "minutely_data['price_volatility_3'] = minutely_data['return'].rolling(parameter_price_volatility_3_window).std(0).shift(1)\n",
    "\n",
    "parameter_zscore_price_volatility_1_window = 15*60*24\n",
    "parameter_zscore_price_volatility_2_window = 15*60*24\n",
    "parameter_zscore_price_volatility_3_window = 15*60*24\n",
    "\n",
    "minutely_data['zscore_price_volatility_1'] = zscore(minutely_data['price_volatility_1'], parameter_zscore_price_volatility_1_window)\n",
    "minutely_data['zscore_price_volatility_2'] = zscore(minutely_data['price_volatility_2'], parameter_zscore_price_volatility_2_window)\n",
    "minutely_data['zscore_price_volatility_3'] = zscore(minutely_data['price_volatility_3'], parameter_zscore_price_volatility_3_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change in volatility\n",
    "\n",
    "parameter_change_in_volatility_top_standard_deviation_1_window = 15\n",
    "parameter_change_in_volatility_top_standard_deviation_2_window = 60\n",
    "\n",
    "parameter_change_in_volatility_bottom_standard_deviation_1_window = 15\n",
    "parameter_change_in_volatility_bottom_standard_deviation_2_window = 60\n",
    "\n",
    "parameter_change_in_volatility_average_bottom_standard_deviation_1_window = 60\n",
    "parameter_change_in_volatility_average_bottom_standard_deviation_2_window = 240\n",
    "\n",
    "minutely_data['temp_1'] = minutely_data['return'].rolling(parameter_change_in_volatility_bottom_standard_deviation_1_window).std(0).shift(1)\n",
    "minutely_data['temp_2'] = minutely_data['return'].rolling(parameter_change_in_volatility_bottom_standard_deviation_2_window).std(0).shift(1)\n",
    "\n",
    "minutely_data['change_in_volatility_1'] = minutely_data['return'].rolling(parameter_change_in_volatility_top_standard_deviation_1_window).std(0).shift(1) / minutely_data.temp_1.rolling(parameter_change_in_volatility_average_bottom_standard_deviation_1_window).mean()\n",
    "minutely_data['change_in_volatility_2'] = minutely_data['return'].rolling(parameter_change_in_volatility_top_standard_deviation_2_window).std(0).shift(1) / minutely_data.temp_2.rolling(parameter_change_in_volatility_average_bottom_standard_deviation_2_window).mean()\n",
    "\n",
    "minutely_data = minutely_data.drop(['temp_1','temp_2'], axis=1)\n",
    "\n",
    "parameter_zscore_change_in_volatility_1_window = 15*60*24\n",
    "parameter_zscore_change_in_volatility_2_window = 15*60*24\n",
    "\n",
    "minutely_data['zscore_change_in_volatility_1'] = zscore(minutely_data['change_in_volatility_1'], parameter_zscore_change_in_volatility_1_window)\n",
    "minutely_data['zscore_change_in_volatility_2'] = zscore(minutely_data['change_in_volatility_2'], parameter_zscore_change_in_volatility_2_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Moving average convergence divergence\n",
    "\n",
    "parameter_fast_exponential_moving_average_window = 3*60*24\n",
    "parameter_slow_exponential_moving_average_window = 5*60*24\n",
    "parameter_signal_moving_average_convergence_divergence_window = 1*60*24\n",
    "\n",
    "minutely_data['moving_average_convergence_divergence'] = minutely_data['Close'].ewm(span = parameter_fast_exponential_moving_average_window, min_periods = parameter_fast_exponential_moving_average_window).mean().shift(1) - minutely_data['Close'].ewm(span = parameter_slow_exponential_moving_average_window, min_periods = parameter_slow_exponential_moving_average_window).mean().shift(1)\n",
    "minutely_data['moving_average_convergence_divergence_signal'] = minutely_data['moving_average_convergence_divergence'].ewm(span = parameter_signal_moving_average_convergence_divergence_window, min_periods = parameter_signal_moving_average_convergence_divergence_window).mean()\n",
    "minutely_data['moving_average_convergence_divergence_histogram'] = minutely_data['moving_average_convergence_divergence'] - minutely_data['moving_average_convergence_divergence_signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_zscore_moving_average_convergence_divergence_window = 5*60*24\n",
    "parameter_zscore_moving_average_convergence_divergence_signal_window = 5*60*24\n",
    "parameter_zscore_moving_average_convergence_divergence_histogram_window = 5*60*24\n",
    "\n",
    "minutely_data['zscore_moving_average_convergence_divergence'] = zscore(minutely_data['moving_average_convergence_divergence'], parameter_zscore_moving_average_convergence_divergence_window)\n",
    "minutely_data['zscore_moving_average_convergence_divergence_signal'] = zscore(minutely_data['moving_average_convergence_divergence_signal'], parameter_zscore_moving_average_convergence_divergence_signal_window)\n",
    "minutely_data['zscore_moving_average_convergence_divergence_histogram'] = zscore(minutely_data['moving_average_convergence_divergence_histogram'], parameter_zscore_moving_average_convergence_divergence_histogram_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stochastics\n",
    "\n",
    "parameter_stochastics_k_window = 5*60*24\n",
    "parameter_stochastics_d_window = 3*60*24\n",
    "\n",
    "minutely_data['stochastics_k'] = (minutely_data.Close.shift(1) - minutely_data['Close'].rolling(parameter_stochastics_k_window).min().shift(1)) / (minutely_data['Close'].rolling(parameter_stochastics_k_window).max().shift(1) - minutely_data['Close'].rolling(parameter_stochastics_k_window).min().shift(1))\n",
    "minutely_data['stochastics_d'] = minutely_data['stochastics_k'].rolling(parameter_stochastics_d_window).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_zscore_stochastics_k_window = 5*60*24\n",
    "parameter_zscore_stochastics_d_window = 5*60*24\n",
    "\n",
    "minutely_data['zscore_stochastics_k'] = zscore(minutely_data['stochastics_k'], parameter_zscore_stochastics_k_window)\n",
    "minutely_data['zscore_stochastics_d'] = zscore(minutely_data['stochastics_d'], parameter_zscore_stochastics_d_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import daily data from qunadl\n",
    "\n",
    "def get_json_data_blockchain(link):\n",
    "    return pd.io.json.json_normalize(list(pd.read_json(link)['values']))\n",
    "\n",
    "def get_quandl_data_from_blockchain(name, asset, token):\n",
    "    data = quandl.get(asset, authtoken = token)\n",
    "    data.index = data.index.astype(np.int64) // 10**9\n",
    "    data.index.names = ['Timestamp']\n",
    "    data.rename(columns={'Value': name}, inplace= True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Token and create different datasets\n",
    "\n",
    "token = 'u6Z2ph3bWw3kVxpHRzVf'\n",
    "\n",
    "data_sets = []\n",
    "\n",
    "parameter_zscore_market_capitalization_USD_window = 15\n",
    "parameter_zscore_transaction_volume_USD_window = 15\n",
    "parameter_zscore_bitcoin_supply_window = 15\n",
    "\n",
    "market_capitalization_USD = get_quandl_data_from_blockchain('market_capitalization_USD', 'BCHAIN/MKTCP', token)\n",
    "data_sets.append(market_capitalization_USD)\n",
    "\n",
    "transaction_volume_USD = get_quandl_data_from_blockchain('transaction_volume_USD', 'BCHAIN/ETRVU', token)\n",
    "data_sets.append(transaction_volume_USD)\n",
    "\n",
    "bitcoin_supply = get_quandl_data_from_blockchain('bitcoin_supply', 'BCHAIN/TOTBC', token)\n",
    "data_sets.append(bitcoin_supply)\n",
    "\n",
    "daily_data = pd.concat(data_sets, axis = 1)\n",
    "                       \n",
    "daily_data['zscore_market_capitalization_USD'] = zscore(daily_data['market_capitalization_USD'].shift(1), parameter_zscore_market_capitalization_USD_window)\n",
    "daily_data['zscore_transaction_volume_USD'] = zscore(daily_data['transaction_volume_USD'].shift(1), parameter_zscore_transaction_volume_USD_window)\n",
    "daily_data['zscore_bitcoin_supply'] = zscore(daily_data['bitcoin_supply'].shift(1), parameter_zscore_bitcoin_supply_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate network value to transactions ratio and signal\n",
    "\n",
    "parameter_network_value_to_transactions_ratio_window = 15\n",
    "\n",
    "parameter_zscore_network_value_to_transactions_ratio_window = 15\n",
    "parameter_zscore_network_value_to_transactions_ratio_signal_window = 15\n",
    "\n",
    "daily_data['network_value_to_transactions_ratio'] = daily_data.market_capitalization_USD.shift(1) / daily_data.transaction_volume_USD.shift(1)\n",
    "daily_data['network_value_to_transactions_ratio_moving_average'] = daily_data.network_value_to_transactions_ratio.rolling(parameter_network_value_to_transactions_ratio_window).mean()\n",
    "\n",
    "daily_data['zscore_network_value_to_transactions_ratio'] = zscore(daily_data['network_value_to_transactions_ratio'], parameter_zscore_network_value_to_transactions_ratio_window)\n",
    "daily_data['zscore_network_value_to_transactions_ratio_signal'] = zscore(daily_data['network_value_to_transactions_ratio_moving_average'], parameter_zscore_network_value_to_transactions_ratio_signal_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start:  1422835200  End:  1530057600\n"
     ]
    }
   ],
   "source": [
    "# Have the same start and end dates for the entire dataset\n",
    "\n",
    "minutely_start_stamp = minutely_data.index[0]\n",
    "minutely_end_stamp = minutely_data.index[-1]\n",
    "\n",
    "daily_start_stamp = daily_data.index[0]\n",
    "daily_end_stamp = daily_data.index[-1]\n",
    "\n",
    "#start_stamp = max(minutely_start_stamp, daily_start_stamp)\n",
    "start_stamp = 1422835200\n",
    "end_stamp = min(minutely_end_stamp, daily_end_stamp)\n",
    "\n",
    "minutely_data = minutely_data.loc[start_stamp:end_stamp]\n",
    "daily_data = daily_data.loc[start_stamp:end_stamp]\n",
    "\n",
    "print (\"Start: \", start_stamp,\" End: \", end_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('mode.use_inf_as_null', True):\n",
    "    filtered_minutely_data = minutely_data[minutely_data.isnull().any(axis =1)]\n",
    "    filtered_daily_data = daily_data[daily_data.isnull().any(axis =1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop layers that were used to derive zscores\n",
    "\n",
    "minutely_data = minutely_data.drop(['Open',\n",
    "                                    'High',\n",
    "                                    'Low',\n",
    "                                    'Close',\n",
    "                                    'Volume_(BTC)',\n",
    "                                    'Volume_(Currency)',\n",
    "                                    'Weighted_Price',\n",
    "                                    'price_to_moving_average_price_1', \n",
    "                                    'price_to_moving_average_price_2', \n",
    "                                    'price_to_moving_average_price_3', \n",
    "                                    'moving_average_crossover_1' , \n",
    "                                    'moving_average_crossover_2', \n",
    "                                    'acceleration_1', \n",
    "                                    'acceleration_2', \n",
    "                                    'volume_moving_average_1', \n",
    "                                    'volume_moving_average_2', \n",
    "                                    'volume_moving_average_3', \n",
    "                                    'price_volatility_1',\n",
    "                                    'price_volatility_2', \n",
    "                                    'price_volatility_3', \n",
    "                                    'change_in_volatility_1',\n",
    "                                    'change_in_volatility_2',\n",
    "                                    'moving_average_convergence_divergence', \n",
    "                                    'moving_average_convergence_divergence_signal', \n",
    "                                    'moving_average_convergence_divergence_histogram', \n",
    "                                    'stochastics_k', \n",
    "                                    'stochastics_d' ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daily_data = daily_data.drop(['market_capitalization_USD', \n",
    "                              'transaction_volume_USD', \n",
    "                              'bitcoin_supply', \n",
    "                              'network_value_to_transactions_ratio', \n",
    "                              'network_value_to_transactions_ratio_moving_average'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['return_answer', 'return', 'lagged_return_1', 'lagged_return_2',\n",
       "       'zscore_return', 'zscore_return_1', 'zscore_return_2',\n",
       "       'zscore_lagged_return_1', 'zscore_lagged_return_2',\n",
       "       'zscore_price_to_moving_average_price_1',\n",
       "       'zscore_price_to_moving_average_price_2',\n",
       "       'zscore_price_to_moving_average_price_3',\n",
       "       'zscore_moving_average_crossover_1',\n",
       "       'zscore_moving_average_crossover_2', 'zscore_acceleration_1',\n",
       "       'zscore_acceleration_2', 'zscore_volume_1', 'zscore_volume_2',\n",
       "       'zscore_volume_3', 'zscore_volume_moving_average_1',\n",
       "       'zscore_volume_moving_average_2', 'zscore_volume_moving_average_3',\n",
       "       'zscore_price_volatility_1', 'zscore_price_volatility_2',\n",
       "       'zscore_price_volatility_3', 'zscore_change_in_volatility_1',\n",
       "       'zscore_change_in_volatility_2',\n",
       "       'zscore_moving_average_convergence_divergence',\n",
       "       'zscore_moving_average_convergence_divergence_signal',\n",
       "       'zscore_moving_average_convergence_divergence_histogram',\n",
       "       'zscore_stochastics_k', 'zscore_stochastics_d'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minutely_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data(minutely_data ,daily_data, batch_size, x_window_size, y_window_size):\n",
    "\n",
    "    num_rows = len(minutely_data)\n",
    "\n",
    "    x_minutely_data = []\n",
    "    y_minutely_data = []\n",
    "\n",
    "    x_daily_data = []\n",
    "    y_daily_data = []\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    difference_in_frequency = (1 / (24*60))\n",
    "\n",
    "    while((i + x_window_size + y_window_size) <= num_rows): #changed from num_rows to 20\n",
    "\n",
    "        # Create minutely windows\n",
    "\n",
    "        x_window_minutely_data = minutely_data[i: (i+x_window_size)]\n",
    "        y_window_minutely_data = minutely_data[(i+x_window_size):(i+x_window_size+y_window_size)]\n",
    "\n",
    "        # Determine start days for daily windows\n",
    "\n",
    "        x_daily_start_value = math.ceil(i*difference_in_frequency)\n",
    "        x_daily_end_value = math.floor((i+x_window_size)*difference_in_frequency)\n",
    "\n",
    "        y_daily_start_value = math.ceil((difference_in_frequency * (i+x_window_size)))\n",
    "        y_daily_end_value = math.floor((difference_in_frequency * (i+x_window_size+y_window_size)))\n",
    "\n",
    "        x_window_daily_data = daily_data[x_daily_start_value: x_daily_end_value]\n",
    "        y_window_daily_data = daily_data[y_daily_start_value: y_daily_end_value]\n",
    "\n",
    "        x_window_daily_data = pd.concat([x_window_daily_data, x_window_minutely_data['return_answer']], axis = 1, join = \"outer\")\n",
    "        abs_base_daily_data = x_window_daily_data.iloc[0]   \n",
    "        \n",
    "        x_window_daily_data['return_answer'] = x_window_minutely_data['return_answer']\n",
    "\n",
    "        y_window_daily_data = pd.concat([y_window_daily_data, y_window_minutely_data['return_answer']], axis =1, join =\"outer\")\n",
    "\n",
    "        y_window_daily_data['return_answer'] = y_window_minutely_data['return_answer']\n",
    "        \n",
    "        # Create the average testing values to solve for\n",
    "\n",
    "        minutely_values = list(x_window_minutely_data.columns).index(\"return_answer\")\n",
    "        \n",
    "        y_average_minutely_data = np.nanmean(y_window_minutely_data.values[:, minutely_values])\n",
    "        y_average_daily_data = y_average_minutely_data\n",
    "\n",
    "        x_minutely_data.append(x_window_minutely_data.values)\n",
    "        y_minutely_data.append(y_average_minutely_data)\n",
    "\n",
    "        x_daily_data.append(x_window_daily_data.values)\n",
    "        y_daily_data.append(y_average_daily_data)    \n",
    "\n",
    "        i += 1\n",
    "\n",
    "        # Once there are no more batches\n",
    "\n",
    "        if (i % batch_size == 0):\n",
    "\n",
    "            x_np_arr_minutely_data = np.array(x_minutely_data)\n",
    "            y_np_arr_minutely_data = np.array(y_minutely_data)\n",
    "\n",
    "            x_np_arr_daily_data = np.array(x_daily_data)\n",
    "            y_np_arr_daily_data = np.array(y_daily_data)\n",
    "\n",
    "            x_minutely_data = []\n",
    "            y_minutely_data = []\n",
    "\n",
    "            x_daily_data = []\n",
    "            y_daily_data = []\n",
    "            \n",
    "            yield (x_np_arr_minutely_data, y_np_arr_minutely_data, x_np_arr_daily_data, y_np_arr_daily_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minutely_data = minutely_data\n",
    "daily_data = daily_data\n",
    "batch_size = 512\n",
    "x_window_size = 256\n",
    "y_window_size = 32\n",
    "\n",
    "dropout_rate = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_clean_data(filename_out, minutely_data ,daily_data, batch_size, x_window_size, y_window_size):\n",
    "    \n",
    "    print (\">>>>>>> Creating x & y data files for minutely & daily data ........\",\"\\n\")\n",
    "    data_generation = clean_data(minutely_data=minutely_data, daily_data = daily_data, batch_size = batch_size, x_window_size = x_window_size, y_window_size = y_window_size)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    with h5py.File(filename_out, \"w\") as hf:\n",
    "        x_minutely, y_minutely, x_daily, y_daily = next(data_generation)\n",
    "        \n",
    "        rcount_minutely_x = x_minutely.shape[0]\n",
    "        dset_minutely_x = hf.create_dataset(\"x_minutely\", shape = x_minutely.shape, maxshape = (None, x_minutely.shape[1], x_minutely.shape[2]), chunks = True)\n",
    "        dset_minutely_x[:] = x_minutely\n",
    "                \n",
    "        rcount_minutely_y = y_minutely.shape[0]\n",
    "        dset_minutely_y = hf.create_dataset(\"y_minutely\", shape = y_minutely.shape, maxshape = (None,), chunks = True)\n",
    "        dset_minutely_y[:] = y_minutely\n",
    "                \n",
    "        rcount_daily_x = x_daily.shape[0]\n",
    "        dset_daily_x = hf.create_dataset(\"x_daily\", shape = x_daily.shape, maxshape=(None, x_daily.shape[1], x_daily.shape[2]), chunks = True)\n",
    "        dset_daily_x[:] = x_daily\n",
    "                \n",
    "        rcount_daily_y = y_daily.shape[0]\n",
    "        dset_daily_y = hf.create_dataset(\"y_daily\", shape = y_daily.shape, maxshape=(None,), chunks = True)\n",
    "        dset_daily_y[:] = y_daily\n",
    "                        \n",
    "        for x_minutely_batch, y_minutely_batch, x_daily_batch, y_daily_batch in data_generation:\n",
    "\n",
    "            print (\">>>> Creating data files | Batch: \", i, end =\"\\r\")\n",
    "            print(\"\\n\")\n",
    "\n",
    "            # Minutely data points\n",
    "            \n",
    "            dset_minutely_x.resize(rcount_minutely_x + x_minutely_batch.shape[0], axis = 0)\n",
    "            dset_minutely_x[rcount_minutely_x:] = x_minutely_batch\n",
    "            rcount_minutely_x += x_minutely_batch.shape[0]\n",
    "            \n",
    "            dset_minutely_y.resize(rcount_minutely_y + y_minutely_batch.shape[0], axis = 0)\n",
    "            dset_minutely_y[rcount_minutely_y:] = y_minutely_batch\n",
    "            rcount_minutely_y += y_minutely_batch.shape[0]\n",
    "                        \n",
    "            # Daily data points          \n",
    "\n",
    "            dset_daily_x.resize(rcount_daily_x + x_daily_batch.shape[0], axis =0 )\n",
    "            dset_daily_x[rcount_daily_x:] = x_daily_batch\n",
    "            rcount_daily_x += x_daily_batch.shape[0]\n",
    "            \n",
    "            dset_daily_y.resize(rcount_daily_y + y_daily_batch.shape[0], axis = 0)\n",
    "            dset_daily_y[rcount_daily_y:] = y_daily_batch\n",
    "            rcount_daily_y += y_daily_batch.shape[0]            \n",
    "            \n",
    "            i += 1\n",
    "\n",
    "    print (\">>>>>>> Clean datasets have been created in file: `\", filename_out + \".h5`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#create_clean_data(filename_out = \"clean_data.h5\", minutely_data = minutely_data ,daily_data = daily_data, batch_size = batch_size, x_window_size = x_window_size, y_window_size = y_window_size)\n",
    "\n",
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load From Saved Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to run the code above (Start Here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_clean_data(filename, batch_size, start_index):\n",
    "    with h5py.File(filename, 'r') as hf:\n",
    "        i = start_index\n",
    "        while True:\n",
    "            x_minutely_data = hf[\"x_minutely\"][i:i+batch_size]\n",
    "            y_minutely_data = hf[\"y_minutely\"][i:i+batch_size]\n",
    "            x_daily_data = hf[\"x_daily\"][i:i+batch_size]\n",
    "            y_daily_data = hf[\"y_daily\"][i:i+batch_size]         \n",
    "            i += batch_size\n",
    "            yield (x_minutely_data, y_minutely_data)\n",
    "            \n",
    "            \"\"\"x_daily_data, y_daily_data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_generate_training = generate_clean_data(filename = \"clean_data.h5\", batch_size = 512, start_index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -0.846467\n",
      "2 -0.558348\n",
      "3 0.193369\n",
      "4 1.38644\n",
      "5 2.22658\n",
      "6 2.46676\n",
      "7 2.34207\n",
      "8 2.01049\n",
      "9 1.75559\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for x,y in data_generate_training:\n",
    "    i +=1\n",
    "    if i == 10:\n",
    "        break\n",
    "    print (i,x[511][200][31])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Simple LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Phased LSTM will be implemented later using : https://github.com/fferroni/PhasedLSTM-Keras/blob/master/phased_lstm_keras/PhasedLSTM.py\n",
    "\n",
    "# Simple LSTM will only use minutely data\n",
    "\n",
    "import time\n",
    "from keras.layers import Dense, TimeDistributed, Activation, Dropout, LSTM\n",
    "from keras.models import Sequential, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def architecture(layers, dropout_rate):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(units = layers[1], input_shape = (None, layers[0]), return_sequences = True))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(LSTM(units = layers[2], return_sequences = False))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(units = layers[3]))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.compile(loss = \"mse\", optimizer = \"Adam\")\n",
    "    \n",
    "    print (\">>> Run Time: \", time.time()- start_time)\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_model_threaded(model, data_generate_training, x_window_size, steps_per_epoch, epochs, dropout_rate, fileout):\n",
    "    \n",
    "    model = architecture([ncols, x_window_size, x_window_size, 1], dropout_rate = dropout_rate)\n",
    "    \n",
    "    model.fit_generator(generator = data_generate_training,\n",
    "                       steps_per_epoch = steps_per_epoch,\n",
    "                       epochs = epochs)\n",
    "    \n",
    "    model.save(fileout)\n",
    "    \n",
    "    print (\">>>>> Model trained and saved in\", fileout)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File(\"clean_data.h5\", \"r\") as hf:\n",
    "    nrows = hf[\"x_minutely\"].shape[0]\n",
    "    ncols = hf[\"x_minutely\"].shape[2]\n",
    "    \n",
    "#print (nrows, ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> The clean data has 1786368 data rows. 1423359 rows with 1389 steps per epoch\n"
     ]
    }
   ],
   "source": [
    "training_percentage = 0.796789911149326\n",
    "epochs = 2\n",
    "\n",
    "fileout = \"saved_model.h5\"\n",
    "\n",
    "number_training = int(training_percentage * nrows)\n",
    "steps_per_epoch = int((number_training / epochs) / batch_size)\n",
    "\n",
    "print (\">>> The clean data has\", nrows, \"data rows.\", number_training, \"rows with\", steps_per_epoch, \"steps per epoch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Run Time:  0.031200408935546875\n"
     ]
    }
   ],
   "source": [
    "model = architecture([ncols,x_window_size, x_window_size, 1], dropout_rate = dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#training = threading.Thread(target = fit_model_threaded, args = [model, data_generate_training,  x_window_size, steps_per_epoch, epochs, dropout_rate,fileout ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#training.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_generate_testing = generate_clean_data(filename = \"clean_data.h5\", batch_size = 512, start_index = number_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Testing the model on 363009 data rows with 1389 steps\n"
     ]
    }
   ],
   "source": [
    "number_testing = nrows - number_training\n",
    "steps_per_epoch_test = int((number_testing) / batch_size)\n",
    "\n",
    "print (\">>> Testing the model on\", number_testing, \"data rows with\", steps_per_epoch, \"steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_strip_xy(data_generate_testing, true_values):\n",
    "    for x_minutely, y_minutely in data_generate_testing:\n",
    "        true_values += list(y_minutely)\n",
    "        yield x_minutely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(generator_strip_xy(data_generate_testing, true_values), steps = steps_per_epoch_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-0ec4784f5c66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model_predictions.h5\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdset_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predictions\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdset_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"true_values\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrue_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"model_predictions.h5\", \"w\") as hf:\n",
    "    dset_p = hf.create_dataset(\"predictions\", data = predictions)\n",
    "    dset_y = hf.create_dataset(\"true_values\", data = true_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(predicted_data, true_data):\n",
    "    fig=plt.figure(figsize=(18, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    plt.plot(predicted_data, label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-e569efbe8bd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "plot_results(predictions[:10000], true_values[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_generate_testing = generate_clean_data(filename = \"clean_data.h5\", batch_size = 512, start_index = number_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_x, true_values = next(data_generate_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_sequences_multiple(model, data, window_size, prediction_len):\n",
    "    #Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_len)):\n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[np.newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_multiple = predict_sequences_multiple(\n",
    "    model,\n",
    "    data_x,\n",
    "    data_x[0].shape[0],\n",
    "    y_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results_multiple(predicted_data, true_data, prediction_len):\n",
    "    fig=plt.figure(figsize=(18, 12), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    #Pad the list of predictions to shift it in the graph to it's correct start\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        padding = [None for p in range(i * prediction_len)]\n",
    "        plt.plot(padding + data, label='Prediction')\n",
    "        plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results_multiple(predictions_multiple, true_values, y_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print (\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
